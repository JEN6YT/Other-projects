# -*- coding: utf-8 -*-
"""Project 1_Customer Data Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qLDB1vskvRaMjN5rGzhYarLm5neY3oeK

Why do we need campaigns?
Spend money to do campaigns but to make more money

###################################################################

Campaign types:

Aquisition: Acquire new customer

Revenue Generation: increase revenue by upsell (upgrade plan) or cross sell (customers purchasing different products from the same company)

Retention: decrease attrition (keep customers)

Announcements: service information 

###################################################################

Campaign process:

Strategic Planning: budget, schedule, target customer , research/testing

Campaign Development: develop offer, define cells, select names, etc.

Execution: direct email, social media, app, website, etc.

Performance Analysis and Reporting: performance dashboard, control comparison

For project 1, you will be analyzing how the campaign is doing (performance, target/control comparison) and also be giving advice on making decision based on the data (data distribution). 

Performance analysis report: (presentation)

Who should be our target audience? Why?

Who kind of execution should we follow? Email? Phone call? Website? Why?

Which age group are more willing to buy the product? Why?
"""

# Reading the customer data
import pandas as pd
!pip install pymysql

import pymysql
conn = pymysql.connect(host="1.tcp.ngrok.io",
                       port=21550,
                       user='python202205',
                       passwd='Sparkpython2022summer', 
                       db="Spark_Python_Class")

cur = conn.cursor()
cur.execute("select * from customer_data")

dfcustomer = pd.DataFrame(data=cur.fetchall(), index = None , )
field_names = [i[0] for i in cur.description]
dfcustomer.columns = field_names

cur.close()
conn.close()

# check duplicate rows
dfcustomer.drop_duplicates(['client_id', 'age', 'province', 'job', 'marital', 'education', 'default_activity', 'housing', 'loan', 'balance'], inplace = True)
dfcustomer.sort_values('client_id')

print(dfcustomer['age'].describe())
print('\n')
print(dfcustomer['age'].value_counts())
print('\n')
df = dfcustomer['age'].value_counts()
df.sort_index(ascending = True, inplace = True)
print(df)
print('\n')
print(df.plot())

# Reading the customer data
import pandas as pd
!pip install pymysql

import pymysql
conn = pymysql.connect(host="1.tcp.ngrok.io",
                       port=21550,
                       user='python202205',
                       passwd='Sparkpython2022summer', 
                       db="Spark_Python_Class")

cur = conn.cursor()
cur.execute("select * from customer_data")

dfcustomer = pd.DataFrame(data=cur.fetchall(), index = None , )
field_names = [i[0] for i in cur.description]
dfcustomer.columns = field_names

cur.close()
conn.close()

# check duplicate rows
dfcustomer.drop_duplicates(['client_id', 'age', 'province', 'job', 'marital', 'education', 'default_activity', 'housing', 'loan', 'balance'], inplace = True)
dfcustomer.sort_values('client_id')
print(dfcustomer['province'].describe())
print('\n')
print(dfcustomer['province'].value_counts())
print('\n')
df1 = dfcustomer['province'].value_counts()
df1.sort_index(ascending = True, inplace = True)
print(df1)
print('\n')
#print(df1.plot(kind = 'bar'))
print(df1.plot(kind = 'pie'))

print(dfcustomer['job'].describe())
print('\n')
print(dfcustomer['job'].value_counts())
print('\n')
df2 = dfcustomer['job'].value_counts()
df2.sort_index(ascending = True, inplace = True)
print(df2)
print('\n')
#print(df2.plot(kind = 'bar'))
print(df2.plot(kind = 'pie'))

# Ontario data
# Reading the customer data
import pandas as pd
!pip install pymysql

import pymysql
conn = pymysql.connect(host="1.tcp.ngrok.io",
                       port=21550,
                       user='python202205',
                       passwd='Sparkpython2022summer', 
                       db="Spark_Python_Class")

cur = conn.cursor()
cur.execute("select * from customer_data")

dfcustomer = pd.DataFrame(data=cur.fetchall(), index = None , )
field_names = [i[0] for i in cur.description]
dfcustomer.columns = field_names

cur.close()
conn.close()

# check duplicate rows
dfcustomer.drop_duplicates(['client_id', 'age', 'province', 'job', 'marital', 'education', 'default_activity', 'housing', 'loan', 'balance'], inplace = True)
dfcustomer.sort_values('client_id')

#print(dfcustomer[['province', 'balance']])
#print('\n')
print(dfcustomer[['province', 'balance']].sort_values('province'))
df_province = dfcustomer[['province', 'balance']].sort_values('province')
print(df_province['province'].value_counts())
print('\n')

# Alberta
# #print(df_province[:4987])
# df_AB = df_province[:4987]
# #print('\n')
# print(df_AB['balance'].describe()) #AB info
# print('\n')
# print(df_AB['balance'].sort_values().head())
# print('\n')
# df_AB_dropna = df_AB['balance'].sort_values().dropna()
# print(df_AB_dropna.tail())

# British Columbia
# df_BC = df_province[4987:12895]
# print(df_BC)
# print('\n')
# print(df_BC['balance'].describe()) #BC info
# print('\n')
# print(df_BC['balance'].sort_values().head())
# print('\n')
# df_BC_dropna = df_BC['balance'].sort_values().dropna()
# print(df_BC_dropna.tail())

# Nova Scotia
# df_NS = df_province[12895:14965]
# print(df_NS)
# print('\n')
# print(df_NS['balance'].describe()) #NS info
# print('\n')
# print(df_NS['balance'].sort_values().head())
# print('\n')
# df_NS_dropna = df_NS['balance'].sort_values().dropna()
# print(df_NS_dropna.tail())

# Ontario
# df_ON = df_province[14965:28339]
# print(df_ON)
# print('\n')
# print(df_ON['balance'].describe()) #NS info
# print('\n')
# print(df_ON['balance'].sort_values().head())
# print('\n')
# df_ON_dropna = df_ON['balance'].sort_values().dropna()
# print(df_ON_dropna.tail())

# Other
# df_OT = df_province[28339:33930]
# print(df_OT)
# print('\n')
# print(df_OT['balance'].describe()) #NS info
# print('\n')
# print(df_OT['balance'].sort_values().head())
# print('\n')
# df_OT_dropna = df_OT['balance'].sort_values().dropna()
# print(df_OT_dropna.tail())

# Quebec
df_QC = df_province[33930:43203]
print(df_QC)
print('\n')
print(df_QC['balance'].describe()) #NS info
print('\n')
print(df_QC['balance'].sort_values().head())
print('\n')
df_QC_dropna = df_QC['balance'].sort_values().dropna()
print(df_QC_dropna.tail())

# Reading the customer data
import pandas as pd
!pip install pymysql

import pymysql
conn = pymysql.connect(host="1.tcp.ngrok.io",
                       port=21550,
                       user='python202205',
                       passwd='Sparkpython2022summer', 
                       db="Spark_Python_Class")

cur = conn.cursor()
cur.execute("select * from customer_data")

dfcustomer = pd.DataFrame(data=cur.fetchall(), index = None , )
field_names = [i[0] for i in cur.description]
dfcustomer.columns = field_names

cur.close()
conn.close()

# check duplicate rows
dfcustomer.drop_duplicates(['client_id', 'age', 'province', 'job', 'marital', 'education', 'default_activity', 'housing', 'loan', 'balance'], inplace = True)
dfcustomer.sort_values('client_id')

print(dfcustomer['marital'].describe())
print('\n')
print(dfcustomer['marital'].value_counts())
print('\n')
df3 = dfcustomer['marital'].value_counts()
df3.sort_index(ascending = True, inplace = True)
print(df3)
print('\n')
print(df3.plot(kind = 'pie'))

print(dfcustomer['education'].describe())
print('\n')
print(dfcustomer['education'].value_counts())
print('\n')
df4 = dfcustomer['education'].value_counts()
df4.sort_index(ascending = True, inplace = True)
print(df4)
print('\n')
#print(df4.plot(kind = 'bar'))
print(df4.plot(kind = 'pie'))

print(dfcustomer['housing'].describe())
print('\n')
print(dfcustomer['housing'].value_counts())
print('\n')
df5 = dfcustomer['housing'].value_counts()
df5.sort_index(ascending = True, inplace = True)
print(df5)
print('\n')
print(df5.plot(kind = 'bar'))
#print(df5.plot(kind = 'pie'))

print(dfcustomer['loan'].describe())
print('\n')
print(dfcustomer['loan'].value_counts())
print('\n')
df6 = dfcustomer['loan'].value_counts()
df6.sort_index(ascending = True, inplace = True)
print(df6)
print('\n')
#print(df6.plot(kind = 'bar'))
print(df6.plot(kind = 'pie'))

print(dfcustomer['balance'].describe())
print('\n')
print(dfcustomer['balance'].value_counts())
print('\n')
df7 = dfcustomer['balance'].value_counts()
df7.sort_index(ascending = True, inplace = True)
print(df7)
print('\n')
print(df7.plot())

# Reading the campaign data
import pandas as pd
!pip install pymysql

import pymysql
conn = pymysql.connect(host="1.tcp.ngrok.io",
                       port=21550,
                       user='python202205',
                       passwd='Sparkpython2022summer', 
                       db="Spark_Python_Class")

cur = conn.cursor()
cur.execute("select * from campaign_data")

dfcampaign = pd.DataFrame(data=cur.fetchall(), index = None , )
field_names = [i[0] for i in cur.description]
dfcampaign.columns = field_names

cur.close()
conn.close()

from google.colab import data_table
data_table.enable_dataframe_formatter()


# check duplicate rows
dfcampaign.drop_duplicates(['client_id', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'y'], inplace = True)
dfcampaign.sort_values('client_id')

# join customer data and campaign data together 

import pandas as pd

# Reading the customer data
# import pandas as pd
#!pip install pymysql

import pymysql
conn = pymysql.connect(host="1.tcp.ngrok.io",
                       port=21550,
                       user='python202205',
                       passwd='Sparkpython2022summer', 
                       db="Spark_Python_Class")

cur = conn.cursor()
cur.execute("select * from customer_data")

dfcustomer = pd.DataFrame(data=cur.fetchall(), index = None , )
field_names = [i[0] for i in cur.description]
dfcustomer.columns = field_names

cur.close()
conn.close()

# check duplicate rows
dfcustomer.drop_duplicates(['client_id', 'age', 'province', 'job', 'marital', 'education', 'default_activity', 'housing', 'loan', 'balance'], inplace = True)
dfcustomer.sort_values('client_id')

conn = pymysql.connect(host="1.tcp.ngrok.io",
                       port=21550,
                       user='python202205',
                       passwd='Sparkpython2022summer', 
                       db="Spark_Python_Class")

# Reading the campaign data
cur = conn.cursor()
cur.execute("select * from campaign_data")

dfcampaign = pd.DataFrame(data=cur.fetchall(), index = None , )
field_names = [i[0] for i in cur.description]
dfcampaign.columns = field_names

cur.close()
conn.close()

from google.colab import data_table
data_table.enable_dataframe_formatter()


# check duplicate rows
dfcampaign.drop_duplicates(['client_id', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'y'], inplace = True)
dfcampaign.sort_values('client_id')

pd.set_option('max_rows', 100)
result = pd.merge(dfcustomer, dfcampaign, on = 'client_id', how = 'outer', indicator = True)
#print(result)

# percentage of customers not in the campaign
count = 0
for i in result['_merge']:
  if i == 'left_only':
    count+=1

total = 0
for i in dfcustomer['client_id']:
  total+=1

print(count/total) # 0.029461856627811814

# Reading the customer data
import pandas as pd
#!pip install pymysql

import pymysql
conn = pymysql.connect(host="1.tcp.ngrok.io",
                       port=21550,
                       user='python202205',
                       passwd='Sparkpython2022summer', 
                       db="Spark_Python_Class")

cur = conn.cursor()
cur.execute("select * from customer_data")

dfcustomer = pd.DataFrame(data=cur.fetchall(), index = None , )
field_names = [i[0] for i in cur.description]
dfcustomer.columns = field_names

cur.close()
conn.close()

# check duplicate rows
dfcustomer.drop_duplicates(['client_id', 'age', 'province', 'job', 'marital', 'education', 'default_activity', 'housing', 'loan', 'balance'], inplace = True)


dfcampaign_1 = dfcampaign[['client_id', 'pdays']]
dfcampaign_2 = dfcampaign[['client_id', 'campaign']]
dfcampaign_3 = dfcampaign[['client_id', 'poutcome']]

dfcampaign_1.sort_values(by = 'pdays', inplace = True)
#print(dfcampaign_1)
#print(dfcampaign_1.value_counts('pdays'))
dfcampaign_1_contacted = dfcampaign_1[35883:]
#print(dfcampaign_1_contacted)

result_1 = pd.merge(dfcampaign_1_contacted, dfcustomer, on = 'client_id', how = 'outer', indicator = True)
result_1.to_excel(excel_writer= r'/content/drive/MyDrive/Colab Notebooks/CampaignDataPdays.xlsx')